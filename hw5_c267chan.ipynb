{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8i8Tqq3pyopQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864d4ba6-78c9-42ae-bc24-84896c734081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r hw5-chrischan325/\n",
        "!git clone https://chrischan325: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@github.com/MSCi-541-F22/hw5-chrischan325.git\n"
      ],
      "metadata": {
        "id": "Xcn001PM26MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hw5-chrischan325/\n",
        "!git pull"
      ],
      "metadata": {
        "id": "EtJEkkhA4w2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "56T8w29IL3rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./IndexEngine.py /content/drive/MyDrive/latimes.gz /content/latimes-index-stem t"
      ],
      "metadata": {
        "id": "Mv9HHJmo8Cdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./BM25.py /content/latimes-index-stem/ /content/hw5-chrischan325/queries.txt /content/hw5-chrischan325/hw5-bm25-stem-c267chan.txt t"
      ],
      "metadata": {
        "id": "V_dT_b8gCcV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "VdQygTQpAXCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import GetDoc\n",
        "import re\n",
        "import collections\n",
        "\n",
        "class Document:\n",
        "    def __init__(self):\n",
        "        self.docno = \"\"\n",
        "        self.internal_id = \"\"\n",
        "        self.doc_date = \"\"\n",
        "        self.headline = \"\"\n",
        "        self.graphic = \"\"\n",
        "        self.text = \"\"\n",
        "        self.raw_document = \"\"\n",
        "        self.length = 0\n",
        "\n",
        "def tokenize(string):\n",
        "    tokens = []\n",
        "    string = string.lower()\n",
        "    tokens.extend(re.findall(r'[\\w]+', string))\n",
        "    tokens = ' '.join(tokens)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def remove_html_tags(string):\n",
        "    # use regex to strip tags\n",
        "    formatted_line = re.compile('<.*?>')\n",
        "    return re.sub(formatted_line, '', string).strip()\n",
        "\n",
        "\n",
        "def plain_parsing_doc(raw_doc):\n",
        "    regex_head = \"<HEADLINE>[\\s\\S]+</HEADLINE>\"\n",
        "    regex_text = \"<TEXT>[\\s\\S]+</TEXT>\"\n",
        "    regex_graphic = \"<GRAPHIC>[\\s\\S]+</GRAPHIC>\"\n",
        "\n",
        "    headline = re.findall(regex_head, raw_doc)\n",
        "    text = re.findall(regex_text, raw_doc)\n",
        "    graphic = re.findall(regex_graphic, raw_doc)\n",
        "\n",
        "    headline = remove_html_tags(headline[0]) if headline else \"\"\n",
        "    text = remove_html_tags(text[0]) if text else \"\"\n",
        "    graphic = remove_html_tags(graphic[0]) if graphic else \"\"\n",
        "\n",
        "    final_string = headline + text + graphic\n",
        "    return final_string\n",
        "\n",
        "topicid_docno_dict = collections.defaultdict(dict)\n",
        "\n",
        "with open('/content/hw5-chrischan325/hw5-bm25-stem-c267chan.txt') as file:\n",
        "  for line in file:\n",
        "    l = line.split()\n",
        "    topicid = int(l[0])\n",
        "    docno = l[2]\n",
        "    raw_doc = plain_parsing_doc(GetDoc.extract_given_docno(docno, '/content/latimes-index-stem').raw_document)\n",
        "    topicid_docno_dict[topicid][docno] = raw_doc\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "boRy-BJbWOn8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"castorini/monobert-large-msmarco\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"castorini/monobert-large-msmarco\").to(0)"
      ],
      "metadata": {
        "id": "VOsW1d0sAlfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "query_number = []\n",
        "query_strings = []\n",
        "\n",
        "def extract_query_info(query_number, query_string, file):  # make two lists that store topic number and query string\n",
        "    for i, line in enumerate(file):\n",
        "        if i % 2 == 0:\n",
        "            query_number.append(line.strip())\n",
        "        else:\n",
        "            query_string.append(line)\n",
        "        \n",
        "with open('/content/hw5-chrischan325/queries.txt', \"rt\") as file:\n",
        "    extract_query_info(query_number, query_strings, file)\n",
        "\n",
        "\n",
        "doc_list = []\n",
        "query_list = []\n",
        "for i, query in enumerate(query_strings):\n",
        "  topicid = int(query_number[i])\n",
        "  docno_dict = topicid_docno_dict[topicid]\n",
        "  for docno, raw_doc in docno_dict.items():\n",
        "    doc_list.append(raw_doc)\n",
        "    query_list.append(query)\n",
        "\n",
        "\n",
        "args = TrainingArguments(output_dir=\"temp\", per_device_eval_batch_size=32)\n",
        "tokenized = tokenizer(query_list, doc_list, max_length=512, truncation=\"only_second\")\n",
        "dataset = Dataset.from_dict(tokenized)  \n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(model, args, train_dataset=dataset, data_collator=data_collator, tokenizer=tokenizer)\n",
        "predictions = trainer.predict(dataset)\n",
        "scores = torch.tensor(predictions.predictions).log_softmax(-1)[:, -1]\n",
        "\n",
        "print(scores)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mDMQx2M-BPpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores[:20])\n",
        "\n",
        "score_results = {}\n",
        "\n",
        "i = 0 \n",
        "\n",
        "for topicid, docno_dict in topicid_docno_dict.items():\n",
        "  docno_scores = {}\n",
        "  for docno in docno_dict:\n",
        "    docno_scores[docno] = scores[i]\n",
        "    i += 1\n",
        "  docno_scores = dict(sorted(docno_scores.items(), key=lambda x: x[1], reverse=True))\n",
        "  score_results[topicid] = docno_scores\n",
        "\n",
        "print(\"i: \", i)\n",
        "\n",
        "with open('/content/hw5-chrischan325/hw5-BERT-c267chan.txt', 'wt') as file:\n",
        "  j = 1\n",
        "  for topicid, scores_dict in score_results.items():\n",
        "    for docno, score in scores_dict.items():\n",
        "      file.write(\"{} Q0 {} {} {} c267chan_BERT\\n\".format(topicid, docno, j, score))\n",
        "      print(\"finished: \", docno)\n",
        "      j += 1\n",
        "  \n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "wI-QQO_TuQHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./measure.py /content/hw5-chrischan325/qrels/LA-only.trec8-401.450.minus416-423-437-444-447.txt /content/hw5-chrischan325/hw5-BERT-c267chan.txt"
      ],
      "metadata": {
        "id": "TK-ZcNbxukkw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}